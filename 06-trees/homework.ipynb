{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-02 14:14:44--  https://github.com/alexeygrigorev/datasets/raw/refs/heads/master/jamb_exam_results.csv\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/alexeygrigorev/datasets/refs/heads/master/jamb_exam_results.csv [following]\n",
      "--2024-11-02 14:14:45--  https://raw.githubusercontent.com/alexeygrigorev/datasets/refs/heads/master/jamb_exam_results.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 391501 (382K) [text/plain]\n",
      "Saving to: ‘jamb_exam_results.csv’\n",
      "\n",
      "jamb_exam_results.c 100%[===================>] 382.33K  --.-KB/s    in 0.007s  \n",
      "\n",
      "2024-11-02 14:14:45 (51.8 MB/s) - ‘jamb_exam_results.csv’ saved [391501/391501]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/alexeygrigorev/datasets/raw/refs/heads/master/jamb_exam_results.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/workspaces/ml-zoomcamp/06-trees/jamb_exam_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JAMB_Score</th>\n",
       "      <th>Study_Hours_Per_Week</th>\n",
       "      <th>Attendance_Rate</th>\n",
       "      <th>Teacher_Quality</th>\n",
       "      <th>Distance_To_School</th>\n",
       "      <th>School_Type</th>\n",
       "      <th>School_Location</th>\n",
       "      <th>Extra_Tutorials</th>\n",
       "      <th>Access_To_Learning_Materials</th>\n",
       "      <th>Parent_Involvement</th>\n",
       "      <th>IT_Knowledge</th>\n",
       "      <th>Student_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Socioeconomic_Status</th>\n",
       "      <th>Parent_Education_Level</th>\n",
       "      <th>Assignments_Completed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>22</td>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>12.4</td>\n",
       "      <td>Public</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>Male</td>\n",
       "      <td>Low</td>\n",
       "      <td>Tertiary</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>207</td>\n",
       "      <td>14</td>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>Public</td>\n",
       "      <td>Rural</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>Male</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182</td>\n",
       "      <td>29</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>Public</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>Female</td>\n",
       "      <td>High</td>\n",
       "      <td>Tertiary</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210</td>\n",
       "      <td>29</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>Public</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>High</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>Female</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tertiary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199</td>\n",
       "      <td>12</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>8.8</td>\n",
       "      <td>Public</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>Female</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tertiary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   JAMB_Score  Study_Hours_Per_Week  Attendance_Rate  Teacher_Quality  \\\n",
       "0         192                    22               78                4   \n",
       "1         207                    14               88                4   \n",
       "2         182                    29               87                2   \n",
       "3         210                    29               99                2   \n",
       "4         199                    12               98                3   \n",
       "\n",
       "   Distance_To_School School_Type School_Location Extra_Tutorials  \\\n",
       "0                12.4      Public           Urban             Yes   \n",
       "1                 2.7      Public           Rural              No   \n",
       "2                 9.6      Public           Rural             Yes   \n",
       "3                 2.6      Public           Urban              No   \n",
       "4                 8.8      Public           Urban              No   \n",
       "\n",
       "  Access_To_Learning_Materials Parent_Involvement IT_Knowledge  Student_ID  \\\n",
       "0                          Yes               High       Medium           1   \n",
       "1                          Yes               High         High           2   \n",
       "2                          Yes               High       Medium           3   \n",
       "3                          Yes             Medium         High           4   \n",
       "4                          Yes             Medium       Medium           5   \n",
       "\n",
       "   Age  Gender Socioeconomic_Status Parent_Education_Level  \\\n",
       "0   17    Male                  Low               Tertiary   \n",
       "1   15    Male                 High                    NaN   \n",
       "2   20  Female                 High               Tertiary   \n",
       "3   22  Female               Medium               Tertiary   \n",
       "4   22  Female               Medium               Tertiary   \n",
       "\n",
       "   Assignments_Completed  \n",
       "0                      2  \n",
       "1                      1  \n",
       "2                      2  \n",
       "3                      1  \n",
       "4                      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparation:**\n",
    "\n",
    "- Remove the `student_id` column.\n",
    "- Fill missing values with zeros.\n",
    "- Do train/validation/test split with 60%/20%/20% distribution.\n",
    "- Use the `train_test_split` function and set the `random_state` parameter to `1`.\n",
    "- Use `DictVectorizer(sparse=True)` to turn the dataframes into matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['student_id'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jamb_score                        0\n",
       "study_hours_per_week              0\n",
       "attendance_rate                   0\n",
       "teacher_quality                   0\n",
       "distance_to_school                0\n",
       "school_type                       0\n",
       "school_location                   0\n",
       "extra_tutorials                   0\n",
       "access_to_learning_materials      0\n",
       "parent_involvement                0\n",
       "it_knowledge                      0\n",
       "age                               0\n",
       "gender                            0\n",
       "socioeconomic_status              0\n",
       "parent_education_level          891\n",
       "assignments_completed             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jamb_score                      0\n",
       "study_hours_per_week            0\n",
       "attendance_rate                 0\n",
       "teacher_quality                 0\n",
       "distance_to_school              0\n",
       "school_type                     0\n",
       "school_location                 0\n",
       "extra_tutorials                 0\n",
       "access_to_learning_materials    0\n",
       "parent_involvement              0\n",
       "it_knowledge                    0\n",
       "age                             0\n",
       "gender                          0\n",
       "socioeconomic_status            0\n",
       "parent_education_level          0\n",
       "assignments_completed           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=SEED)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=SEED)\n",
    "\n",
    "assert len(df) == (len(df_train) + len(df_val) + len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1000, 1000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['jamb_score']).to_dict(orient='records')\n",
    "X_val = df_val.drop(columns=['jamb_score']).to_dict(orient='records')\n",
    "X_test = df_test.drop(columns=['jamb_score']).to_dict(orient='records')\n",
    "\n",
    "y_train = df_train['jamb_score']\n",
    "y_val = df_val['jamb_score']\n",
    "y_test = df_test['jamb_score']\n",
    "\n",
    "dv = DictVectorizer(sparse=True)\n",
    "X_train = dv.fit_transform(X_train)\n",
    "X_val = dv.transform(X_val)\n",
    "X_test = dv.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Let's train a decision tree regressor to predict the `jamb_score` variable.\n",
    "\n",
    "- Train a model with `max_depth=1`.\n",
    "\n",
    "Which feature is used for splitting the data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'study_hours_per_week'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(max_depth=1, random_state=SEED)\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "feature_index = dt.tree_.feature[0]\n",
    "feature_name = dv.feature_names_[feature_index]\n",
    "feature_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study_hours_per_week\n"
     ]
    }
   ],
   "source": [
    "for index in dt.tree_.feature:\n",
    "    if index != -2:  # -2 is a leaf node\n",
    "        print(dv.feature_names_[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Train a random forest model with these parameters:\n",
    "\n",
    "- `n_estimators=10`\n",
    "- `random_state=1`\n",
    "- `n_jobs=-1` (optional - to make training faster)\n",
    "\n",
    "What's the RMSE of this model on validation?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(42.13724207871227)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val = rf.predict(X_val)\n",
    "\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "rmse_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Now let's experiment with the `n_estimators` parameter\n",
    "\n",
    "- Try different values of this parameter from 10 to 200 with step 10.\n",
    "- Set `random_state` to `1`.\n",
    "- Evaluate the model on the validation dataset.\n",
    "\n",
    "After which value of `n_estimators` does RMSE stop improving? Consider 3 decimal places for calculating the answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 10, RMSE: 42.137\n",
      "n_estimators: 20, RMSE: 41.461\n",
      "n_estimators: 30, RMSE: 41.106\n",
      "n_estimators: 40, RMSE: 40.917\n",
      "n_estimators: 50, RMSE: 40.852\n",
      "n_estimators: 60, RMSE: 40.784\n",
      "n_estimators: 70, RMSE: 40.677\n",
      "n_estimators: 80, RMSE: 40.539\n",
      "n_estimators: 90, RMSE: 40.504\n",
      "n_estimators: 100, RMSE: 40.517\n",
      "n_estimators: 110, RMSE: 40.593\n",
      "n_estimators: 120, RMSE: 40.625\n",
      "n_estimators: 130, RMSE: 40.651\n",
      "n_estimators: 140, RMSE: 40.595\n",
      "n_estimators: 150, RMSE: 40.597\n",
      "n_estimators: 160, RMSE: 40.604\n",
      "n_estimators: 170, RMSE: 40.628\n",
      "n_estimators: 180, RMSE: 40.641\n",
      "n_estimators: 190, RMSE: 40.631\n",
      "n_estimators: 200, RMSE: 40.601\n",
      "n_estimators: 210, RMSE: 40.520\n",
      "Initial RMSE: 42.137\n",
      "Comparing prev_rmse: 42.137 with current rmse: 41.461\n",
      "Comparing prev_rmse: 41.461 with current rmse: 41.106\n",
      "Comparing prev_rmse: 41.106 with current rmse: 40.917\n",
      "Comparing prev_rmse: 40.917 with current rmse: 40.852\n",
      "Comparing prev_rmse: 40.852 with current rmse: 40.784\n",
      "Comparing prev_rmse: 40.784 with current rmse: 40.677\n",
      "Comparing prev_rmse: 40.677 with current rmse: 40.539\n",
      "Comparing prev_rmse: 40.539 with current rmse: 40.504\n",
      "Comparing prev_rmse: 40.504 with current rmse: 40.517\n",
      "Comparing prev_rmse: 40.517 with current rmse: 40.593\n",
      "Comparing prev_rmse: 40.593 with current rmse: 40.625\n",
      "Comparing prev_rmse: 40.625 with current rmse: 40.651\n",
      "Comparing prev_rmse: 40.651 with current rmse: 40.595\n",
      "Comparing prev_rmse: 40.595 with current rmse: 40.597\n",
      "Comparing prev_rmse: 40.597 with current rmse: 40.604\n",
      "Comparing prev_rmse: 40.604 with current rmse: 40.628\n",
      "Comparing prev_rmse: 40.628 with current rmse: 40.641\n",
      "Comparing prev_rmse: 40.641 with current rmse: 40.631\n",
      "Comparing prev_rmse: 40.631 with current rmse: 40.601\n",
      "Comparing prev_rmse: 40.601 with current rmse: 40.520\n"
     ]
    }
   ],
   "source": [
    "n_estimators_range = range(10, 220, 10)\n",
    "rmse_values = []\n",
    "\n",
    "for n in n_estimators_range:\n",
    "    rf = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_val = rf.predict(X_val)\n",
    "    \n",
    "    rmse_val = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "    rmse_values.append((n, rmse_val))\n",
    "\n",
    "for n, rmse in rmse_values:\n",
    "    print(f\"n_estimators: {n}, RMSE: {rmse:.3f}\")\n",
    "\n",
    "threshold = 0.001  \n",
    "prev_rmse = rmse_values[0][1]\n",
    "print(f\"Initial RMSE: {prev_rmse:.3f}\")  # Debugguing print\n",
    "\n",
    "for i, (n, rmse) in enumerate(rmse_values[1:], start=1):\n",
    "    print(f\"Comparing prev_rmse: {prev_rmse:.3f} with current rmse: {rmse:.3f}\")  # Debugging print\n",
    "    if abs(prev_rmse - rmse) < threshold:\n",
    "        print(f\"RMSE stops improving after n_estimators = {n}\")\n",
    "        break\n",
    "    prev_rmse = rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "Let's select the best `max_depth`:\n",
    "\n",
    "- Try different values of `max_depth`: [10, 15, 20, 25]\n",
    "- For each of these values,\n",
    "- try different values of `n_estimators` from 10 till 200 (with step 10)\n",
    "- calculate the mean RMSE\n",
    "- Fix the random seed: `random_state=1`\n",
    "\n",
    "What's the best `max_depth`, using the mean RMSE?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 10, Mean RMSE: 40.392\n",
      "max_depth: 15, Mean RMSE: 40.735\n",
      "max_depth: 20, Mean RMSE: 40.740\n",
      "max_depth: 25, Mean RMSE: 40.788\n",
      "Best max_depth: 10 with Mean RMSE: 40.392\n"
     ]
    }
   ],
   "source": [
    "max_depth_values = [10, 15, 20, 25]\n",
    "n_estimators_range = range(10, 210, 10)\n",
    "random_state = 1\n",
    "\n",
    "mean_rmse_results = {}\n",
    "\n",
    "for max_depth in max_depth_values:\n",
    "    rmse_list = []\n",
    "    \n",
    "    for n_estimators in n_estimators_range:\n",
    "        rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state, n_jobs=-1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred_val = rf.predict(X_val)\n",
    "        rmse_val = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "        rmse_list.append(rmse_val)\n",
    "    \n",
    "    mean_rmse = np.mean(rmse_list)\n",
    "    mean_rmse_results[max_depth] = mean_rmse\n",
    "\n",
    "for depth, mean_rmse in mean_rmse_results.items():\n",
    "    print(f\"max_depth: {depth}, Mean RMSE: {mean_rmse:.3f}\")\n",
    "\n",
    "best_max_depth = min(mean_rmse_results, key=mean_rmse_results.get)\n",
    "best_mean_rmse = mean_rmse_results[best_max_depth]\n",
    "\n",
    "print(f\"Best max_depth: {best_max_depth} with Mean RMSE: {best_mean_rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**\n",
    "\n",
    "We can extract feature importance information from tree-based models.\n",
    "\n",
    "At each step of the decision tree learning algorithm, it finds the best split. When doing it, we can calculate \"gain\" - the reduction in impurity before and after the split. This gain is quite useful in understanding what are the important features for tree-based models.\n",
    "\n",
    "In Scikit-Learn, tree-based models contain this information in the feature_importances_ field.\n",
    "\n",
    "For this homework question, we'll find the most important feature:\n",
    "<ul>\n",
    "<li>Train the model with these parameters:</li>\n",
    "<ul>\n",
    "<li><code>n_estimators=10</code>,</li>\n",
    "<li><code>max_depth=20</code>,</li>\n",
    "<li><code>random_state=1</code>,</li>\n",
    "<li><code>n_jobs=-1 (optional)</code></li>\n",
    "</ul>\n",
    "</ul>\n",
    "Get the feature importance information from this model\n",
    "\n",
    "What's the most important feature (among these 4)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: study_hours_per_week, Importance: 0.2484\n",
      "Feature: attendance_rate, Importance: 0.1497\n",
      "Feature: distance_to_school, Importance: 0.1365\n",
      "Feature: teacher_quality, Importance: 0.0827\n",
      "Feature: age, Importance: 0.0693\n",
      "Feature: assignments_completed, Importance: 0.0315\n",
      "Feature: socioeconomic_status=High, Importance: 0.0257\n",
      "Feature: parent_involvement=High, Importance: 0.0229\n",
      "Feature: it_knowledge=High, Importance: 0.0177\n",
      "Feature: parent_education_level=Secondary, Importance: 0.0170\n",
      "Feature: parent_education_level=Primary, Importance: 0.0155\n",
      "Feature: parent_education_level=Tertiary, Importance: 0.0145\n",
      "Feature: extra_tutorials=No, Importance: 0.0135\n",
      "Feature: parent_involvement=Low, Importance: 0.0134\n",
      "Feature: it_knowledge=Low, Importance: 0.0124\n",
      "Feature: access_to_learning_materials=No, Importance: 0.0123\n",
      "Feature: parent_involvement=Medium, Importance: 0.0115\n",
      "Feature: socioeconomic_status=Low, Importance: 0.0107\n",
      "Feature: socioeconomic_status=Medium, Importance: 0.0106\n",
      "Feature: gender=Male, Importance: 0.0104\n",
      "Feature: access_to_learning_materials=Yes, Importance: 0.0103\n",
      "Feature: school_location=Rural, Importance: 0.0096\n",
      "Feature: gender=Female, Importance: 0.0093\n",
      "Feature: school_location=Urban, Importance: 0.0092\n",
      "Feature: it_knowledge=Medium, Importance: 0.0091\n",
      "Feature: extra_tutorials=Yes, Importance: 0.0091\n",
      "Feature: school_type=Private, Importance: 0.0090\n",
      "Feature: school_type=Public, Importance: 0.0084\n",
      "Feature: parent_education_level, Importance: 0.0000\n",
      "\n",
      "Most important feature: study_hours_per_week with importance: 0.2484\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 10\n",
    "max_depth = 20\n",
    "random_state = 1\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "feature_names = dv.get_feature_names_out()\n",
    "\n",
    "feature_importance_list = list(zip(feature_names, importances))\n",
    "\n",
    "sorted_features = sorted(feature_importance_list, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for feature, importance in sorted_features:\n",
    "    print(f\"Feature: {feature}, Importance: {importance:.4f}\")\n",
    "\n",
    "most_important_feature = sorted_features[0]\n",
    "print(f\"\\nMost important feature: {most_important_feature[0]} with importance: {most_important_feature[1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE can go more specific using the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "study_hours_per_week: Importance = 0.2484\n",
      "attendance_rate: Importance = 0.1497\n",
      "distance_to_school: Importance = 0.1365\n",
      "teacher_quality: Importance = 0.0827\n",
      "\n",
      "Most Important Feature: study_hours_per_week with Importance = 0.2484\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 10\n",
    "max_depth = 20\n",
    "random_state = 1\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "feature_names = dv.get_feature_names_out()\n",
    "\n",
    "feature_importance_dict = dict(zip(feature_names, importances))\n",
    "\n",
    "specific_features = ['study_hours_per_week', 'attendance_rate', 'distance_to_school', 'teacher_quality']\n",
    "\n",
    "specific_importances = {feature: feature_importance_dict.get(feature, 0) for feature in specific_features}\n",
    "\n",
    "most_important_feature = max(specific_importances, key=specific_importances.get)\n",
    "most_important_importance = specific_importances[most_important_feature]\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "for feature, importance in specific_importances.items():\n",
    "    print(f\"{feature}: Importance = {importance:.4f}\")\n",
    "\n",
    "print(f\"\\nMost Important Feature: {most_important_feature} with Importance = {most_important_importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6**\n",
    "\n",
    "Now let's train an XGBoost model! For this question, we'll tune the eta parameter:\n",
    "\n",
    "- Install XGBoost\n",
    "- Create DMatrix for train and validation\n",
    "- Create a watchlist\n",
    "- Train a model with these parameters for 100 rounds:\n",
    "```\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "```\n",
    "Now change `eta` from `0.3` to `0.1`.\n",
    "\n",
    "Which eta leads to the best RMSE score on the validation dataset?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.2-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from xgboost) (2.1.0)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Downloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.12/site-packages (from xgboost) (1.14.0)\n",
      "Downloading xgboost-2.1.2-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl (199.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
      "Successfully installed nvidia-nccl-cu12-2.23.4 xgboost-2.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for eta = 0.3: 43.4188\n",
      "RMSE for eta = 0.1: 41.0503\n",
      "Best eta is 0.1\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Define XGBoost parameters for eta = 0.3\n",
    "xgb_params_0_3 = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model_0_3 = xgb.XGBRegressor(**xgb_params_0_3, n_estimators=100)\n",
    "\n",
    "model_0_3.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val_0_3 = model_0_3.predict(X_val)\n",
    "\n",
    "rmse_0_3 = np.sqrt(mean_squared_error(y_val, y_pred_val_0_3))\n",
    "print(f\"RMSE for eta = 0.3: {rmse_0_3:.4f}\")\n",
    "\n",
    "# Define XGBoost parameters for eta = 0.1\n",
    "xgb_params_0_1 = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model_0_1 = xgb.XGBRegressor(**xgb_params_0_1, n_estimators=100)\n",
    "\n",
    "model_0_1.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val_0_1 = model_0_1.predict(X_val)\n",
    "\n",
    "rmse_0_1 = np.sqrt(mean_squared_error(y_val, y_pred_val_0_1))\n",
    "print(f\"RMSE for eta = 0.1: {rmse_0_1:.4f}\")\n",
    "\n",
    "# Compare RMSE results\n",
    "if rmse_0_3 < rmse_0_1:\n",
    "    print(\"Best eta is 0.3\")\n",
    "else:\n",
    "    print(\"Best eta is 0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
